{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Projet Data Science: Prédiction des Prix Immobiliers - USE CASE\n",
    "\n",
    "Nous sommes un fonds d'investissement actif sur le marché immobilier, cherchant à augmenter nos revenus en identifiant des opportunités immobilières sous-évaluées. Notre objectif principal est de trouver des biens immobiliers sous-évalués, de les acheter, et de les revendre ultérieurement pour réaliser une marge bénéficiaire significative. Pour atteindre cet objectif, nous développons un modèle de machine learning capable de prédire avec précision les prix des maisons en fonction de diverses caractéristiques telles que la taille de la maison, l'emplacement, et d'autres attributs pertinents.\n",
    "\n",
    "#### Sources de données\n",
    "\n",
    "Nous collaborons avec des agences immobilières locales pour obtenir des listings détaillés de propriétés, des données historiques de ventes, et des conditions actuelles du marché. Les agences immobilières sont des partenaires clés car elles possèdent des informations précises et à jour sur le marché immobilier local. Cette collaboration nous permet d'accéder à des données riches et variées, incluant les caractéristiques physiques des maisons (surface habitable, nombre de chambres, salles de bains, etc.) et les prix de vente historiques pour des propriétés similaires dans la même zone géographique.\n",
    "\n",
    "#### Collecte de données\n",
    "\n",
    "La collecte de données consiste à rassembler des ensembles de données complets et à jour auprès des agences immobilières, incluant les caractéristiques des propriétés, les données transactionnelles historiques et les conditions du marché. Le nettoyage et le prétraitement des données assurent la qualité des données. Nous gérons les valeurs manquantes en utilisant des techniques d'imputation appropriées, normalisons les caractéristiques pour assurer la comparabilité, et transformons les variables catégorielles en variables numériques à l'aide de techniques d'encodage telles que l'encodage one-hot.\n",
    "\n",
    "#### Construction du modèle\n",
    "\n",
    "Pour développer notre modèle, nous explorons différentes techniques de régression. Nous utilisons des modèles de régression linéaire pour établir une relation entre les caractéristiques des propriétés et leur prix de vente. Nous explorons également des modèles avancés de régression tels que Ridge, Lasso, et ElasticNet pour améliorer la précision. Ces modèles sont choisis pour leur capacité à gérer des données multivariées et à éviter le sur-ajustement en pénalisant les coefficients de régression.\n",
    "\n",
    "L'entraînement et l'évaluation du modèle se font en divisant les données en ensembles d'entraînement et de test. Nous utilisons la métrique RMSLE (Root Mean Squared Logarithmic Error) pour mesurer la précision des prédictions. Cette métrique est choisie car elle pénalise proportionnellement les grandes erreurs, ce qui est adapté à la prédiction des prix immobiliers.\n",
    "\n",
    "Le déploiement du modèle dans un environnement de production permet des prédictions en temps réel. L'intégration du modèle dans des interfaces utilisateur conviviales facilite son utilisation par nos décideurs internes, qu'ils soient membres de notre équipe d'investissement ou analystes financiers.\n",
    "\n",
    "#### Proposition de Valeur\n",
    "\n",
    "Pour les agences immobilières, notre modèle accélère le processus de vente en fournissant des prédictions de prix précises, permettant ainsi de mettre en place des stratégies de tarification compétitives. Cela réduit le temps de vente et augmente la satisfaction des clients.\n",
    "\n",
    "Pour les investisseurs, notre modèle identifie les propriétés sous-évaluées, offrant ainsi des opportunités d'investissement avec un potentiel de retour sur investissement élevé. En utilisant des prédictions de prix précises, les investisseurs peuvent gérer les risques et optimiser leurs stratégies d'investissement avec un objectif de marge bénéficiaire de 20%.\n",
    "\n",
    "Pour les vendeurs de biens immobiliers, notre modèle offre la possibilité de vendre rapidement sans avoir à passer des mois à chercher un acheteur. Ils ont un partenaire avec des ressources financières prêtes à acheter immédiatement. Nous, en tant que fonds d'investissement, prenons les risques.\n",
    "\n",
    "#### Décisions\n",
    "\n",
    "Les agences immobilières bénéficient de cycles de vente plus rapides et de meilleures stratégies de tarification, ce qui améliore leur efficacité opérationnelle et leur compétitivité sur le marché.\n",
    "\n",
    "Notre équipe d'investissement utilise les prédictions pour identifier et investir dans des propriétés sous-évaluées, maximisant ainsi les retours sur investissement et optimisant notre portefeuille immobilier.\n",
    "\n",
    "#### Tâches de prédiction\n",
    "\n",
    "Les données de haute qualité sur les propriétés et les transactions fournies par les agences immobilières sont essentielles pour la précision du modèle. La technologie utilisée comprend une infrastructure robuste de machine learning pour l'entraînement et le déploiement du modèle. L'expertise combinée de data scientists et d'experts immobiliers est nécessaire pour développer et affiner les modèles de prédiction, garantissant ainsi des résultats fiables et actionnables.\n",
    "\n",
    "#### Faire des prédictions\n",
    "\n",
    "Les modèles sont réajustés en fonction des retours sur investissements réels et des nouvelles données collectées. Cela permet de maintenir la précision et la pertinence du modèle dans un marché immobilier dynamique.\n",
    "\n",
    "#### Simulation d'impact\n",
    "\n",
    "Nous simulons des scénarios d'achat et de vente pour évaluer l'impact des prédictions de prix sur les décisions d'investissement. Ces simulations sont basées sur des scénarios réels et permettent d'optimiser les stratégies d'achat et de vente en fonction des prédictions du modèle.\n",
    "\n",
    "#### Attributs (features)\n",
    "\n",
    "Les attributs utilisés pour les prédictions incluent des caractéristiques détaillées des propriétés telles que la localisation, la taille, l'état général, et les équipements disponibles. À l'avenir, nous envisageons d'inclure des facteurs externes comme les tendances du marché et les taux d'intérêt.\n",
    "\n",
    "#### Indicateurs Clés (live monitoring)\n",
    "\n",
    "##### Précision du Modèle (RMSLE)\n",
    "\n",
    "La précision du modèle est mesurée en utilisant la métrique RMSLE (Root Mean Squared Logarithmic Error). Voici pourquoi cette métrique est appropriée pour notre cas d'utilisation :\n",
    "\n",
    "1. **Gestion des grandes erreurs** : La RMSLE pénalise proportionnellement les grandes erreurs. Dans le contexte de la prédiction des prix immobiliers, les grandes erreurs peuvent entraîner des décisions d'investissement très coûteuses. Par exemple, surévaluer ou sous-évaluer significativement une propriété peut entraîner des pertes importantes. La RMSLE assure que ces erreurs sont prises en compte de manière stricte, ce qui améliore la fiabilité des prédictions.\n",
    "\n",
    "2. **Échelle logarithmique** : En utilisant une échelle logarithmique, la RMSLE atténue l'impact des grandes valeurs aberrantes. Dans le marché immobilier, il peut y avoir des propriétés avec des prix extrêmement élevés ou bas qui pourraient influencer les résultats de manière disproportionnée. La transformation logarithmique aide à stabiliser la variance et à traiter les grandes valeurs de manière plus équilibrée.\n",
    "\n",
    "3. **Comparabilité des erreurs** : La RMSLE permet de comparer les erreurs de prédiction de manière relative plutôt qu'absolue. Cela signifie que les erreurs pour des propriétés moins chères et plus chères sont traitées de manière équitable. Pour un fonds d'investissement, il est important de maintenir une précision uniforme sur toute la gamme de prix des propriétés.\n",
    "\n",
    "##### Marge Bénéficiaire\n",
    "\n",
    "La marge bénéficiaire est suivie pour mesurer le profit réalisé à partir des investissements immobiliers identifiés par le modèle. Cet indicateur clé permet de :\n",
    "\n",
    "1. **Évaluer la performance financière** : En suivant la marge bénéficiaire, nous pouvons mesurer l'efficacité de notre modèle en termes de retour sur investissement. Cela nous aide à comprendre combien nous gagnons par rapport au capital investi dans les propriétés.\n",
    "\n",
    "2. **Optimiser les stratégies d'investissement** : En analysant la marge bénéficiaire, nous pouvons identifier quelles stratégies d'achat et de vente sont les plus rentables. Cela nous permet d'ajuster notre approche pour maximiser les profits.\n",
    "\n",
    "3. **Suivi en temps réel** : La surveillance en temps réel de la marge bénéficiaire nous permet de réagir rapidement aux changements du marché immobilier. Si nous constatons que les marges bénéficiaires diminuent, nous pouvons immédiatement réévaluer notre modèle et nos stratégies d'investissement pour corriger le tir.\n",
    "\n",
    "Ces indicateurs clés sont surveillés en temps réel pour assurer la performance et l'efficacité du modèle. La surveillance en temps réel est essentielle pour détecter rapidement les anomalies, ajuster les modèles en fonction des nouvelles données, et garantir que les prédictions restent précises et pertinentes dans un marché immobilier en constante évolution.\n",
    "\n",
    "---"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "xjY6DJLGDrwAc3IBjEE5tP",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install optuna\n",
    "#!pip install catboost\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install xgboost\n",
    "#!pip install catboost\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn\n",
    "#!pip install optuna\n",
    "#!pip install scipy\n",
    "#!pip install scikit-learn\n",
    "#!pip install category_encoders\n",
    "#!pip install lightgbm\n",
    "#!pip install shap\n",
    "#!pip install kaggle\n",
    "!pip install mlflow\n",
    "!pip install setuptools"
   ],
   "metadata": {
    "datalore": {
     "node_id": "FOsfR4wngaALqsUKBPypfb",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "2BCUkfdjtpygtAEUi0scYJ"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import catboost\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna.visualization as vis\n",
    "import shap\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import json"
   ],
   "metadata": {
    "datalore": {
     "node_id": "wmRapl4fl5LHEqvC9XqxE1",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploration Initiale des Données\n",
    "\n",
    "Pour comprendre et explorer les données disponibles dans notre projet de prédiction des prix immobiliers, nous effectuons une série de manipulations initiales sur la DataFrame. Voici une explication et une justification pour chaque étape :\n",
    "\n",
    "#### Chargement des Données\n",
    "\n",
    "Nous chargeons les données à partir du fichier `train.csv` en utilisant la colonne `Id` comme index de la DataFrame. Cela permet d'identifier chaque enregistrement de manière unique, facilitant la manipulation et l'analyse ultérieure.\n",
    "\n",
    "#### Affichage des Premières Lignes\n",
    "\n",
    "Nous affichons les cinq premières lignes de la DataFrame pour obtenir un aperçu rapide de la structure des données et vérifier que le fichier a été chargé correctement. Cela permet d'identifier les types de colonnes et les premières valeurs.\n"
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "mUmzZiZot4POv1bEPpp6ca",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col= \"Id\")\n",
    "train.head(5)"
   ],
   "metadata": {
    "datalore": {
     "node_id": "5ZXAMLzY8BzihUlChLG7At",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Informations Générales sur la DataFrame\n",
    "\n",
    "Nous obtenons un résumé concis de la DataFrame, incluant le nombre total d'entrées, le nombre de colonnes, le type de données de chaque colonne et la quantité de valeurs non nulles. Cela aide à comprendre la structure des données et à planifier le prétraitement nécessaire."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "IgTvFwDGJMMxVaxF9tfB7a",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train.info()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "YIM7eQPFyHGK8kq2sTPB5b",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comptage des Valeurs Manquantes\n",
    "\n",
    "Nous calculons le nombre de valeurs manquantes pour chaque colonne afin d'identifier les colonnes avec des données manquantes. Cela est crucial pour décider des stratégies de traitement des valeurs manquantes, comme l'imputation ou la suppression."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "GMzNz7I7LHDT6F30Dykw2X",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train.isna().sum()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "QClQtBf3J9KLqh0Wna73Cx",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Forme de la DataFrame\n",
    "\n",
    "Nous vérifions les dimensions de la DataFrame pour connaître le nombre total de lignes et de colonnes. Cela permet de comprendre l'ampleur des données disponibles et de planifier les ressources nécessaires pour le traitement."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "TEmcy1swezepqXDX1LbV56",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train.shape"
   ],
   "metadata": {
    "datalore": {
     "node_id": "7VpqcOLzkAeZoOWIVlHduU",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Statistiques Descriptives\n",
    "\n",
    "Nous obtenons des statistiques descriptives pour toutes les colonnes, ce qui permet d'explorer la distribution des données, les valeurs centrales et la dispersion. Ces statistiques sont essentielles pour identifier les anomalies et orienter les décisions de prétraitement."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "NVINS28RpVtq2J0aSzTYKn",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train.describe(include=\"all\")"
   ],
   "metadata": {
    "datalore": {
     "node_id": "bfKQQAjNHzAOx1iruJyvKT",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Pourcentage de Valeurs Manquantes\n",
    "\n",
    "Nous calculons le pourcentage de valeurs manquantes pour chaque colonne et trions les résultats par ordre décroissant. Cela aide à évaluer l'impact des données manquantes et à prioriser les efforts de nettoyage, en se concentrant sur les colonnes les plus affectées."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "HMnq1cC6H3SIeHzwYShrSp",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_na = train.isna().sum().reset_index(name=\"missing values\")\n",
    "train_na[\"%\"] = round((train_na[\"missing values\"] / train.shape[0])*100, 2)\n",
    "train_na.sort_values(by=\"%\", ascending=False)"
   ],
   "metadata": {
    "datalore": {
     "node_id": "HYUbALWKnZFPAzLNi9oSqF",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modèle Baseline : Explication et Justification\n",
    "\n",
    "#### Sélection des Features\n",
    "\n",
    "Les features choisies sont : `OverallQual`, `OverallCond`, `GrLivArea`, `TotalBsmtSF`, `GarageArea`, `FullBath`, `HalfBath`, et `BedroomAbvGr`. Elles sont des indicateurs clés de la valeur d'une propriété, reflétant la qualité, la condition, et la taille de la maison. Elles ont été sélectionnées par un expert immobilier pour leur importance dans la détermination des prix des maisons.\n",
    "\n",
    "#### Transformation Logarithmique de la Variable Cible\n",
    "\n",
    "La variable cible `SalePrice` est transformée logarithmiquement (`np.log1p`) pour normaliser sa distribution, améliorant ainsi la performance du modèle.\n",
    "\n",
    "#### Modèle de Régression Linéaire\n",
    "\n",
    "Le modèle de régression linéaire est utilisé comme modèle de base en raison de sa simplicité et pour servir de point de référence.\n",
    "\n",
    "#### Validation Croisée\n",
    "\n",
    "La validation croisée à 5 plis (`cv=5`) est utilisée pour évaluer le modèle, avec la métrique RMSLE (Root Mean Squared Logarithmic Error) pour pénaliser proportionnellement les grandes erreurs.\n",
    "\n",
    "#### Justification du Modèle Baseline\n",
    "\n",
    "1. **Point de Référence** : Le modèle baseline fournit un point de comparaison pour évaluer les améliorations apportées par des modèles plus complexes.\n",
    "2. **Validation des Hypothèses** : Il permet de vérifier les hypothèses de la régression linéaire, telles que la linéarité, la normalité des résidus, l'homoscedasticité et l'absence de multicolinéarité.\n",
    "3. **Évaluation de la Simplicité** : En utilisant un modèle simple, nous pouvons rapidement identifier les problèmes potentiels dans les données.\n",
    "4. **Identification des Problèmes de Données** : Les résultats du modèle baseline peuvent indiquer des relations non linéaires ou des variables manquantes importantes, nécessitant un traitement plus approfondi.\n",
    "\n",
    "Le modèle de base est essentiel pour orienter le développement et l'amélioration de modèles prédictifs plus sophistiqués."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "IJnmU5smDFwzlOMtMoiWg1",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select features for the baseline model\n",
    "features = ['OverallQual', 'OverallCond', 'GrLivArea', 'GarageArea',\n",
    "            'FullBath', 'BedroomAbvGr']\n",
    "X = train[features]\n",
    "y = np.log1p(train['SalePrice'])  # Log transform the target variable\n",
    "\n",
    "# Define the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Cross-validation of the model\n",
    "cv_scores = cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# Convert the negative mean squared log error to positive RMSLE\n",
    "rmsle_cv_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "# Output of the scores\n",
    "print(\"CV Scores: \", rmsle_cv_scores)\n",
    "# Output of the average score\n",
    "print(\"Average CV Score: \", np.mean(rmsle_cv_scores))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Validation des hypothèses de la régression linéaire\n",
    "\n",
    "#### Tracé des résidus par rapport aux prédicteurs\n",
    "\n",
    "Nous traçons les résidus par rapport à chaque feature sélectionnée pour vérifier les hypothèses de la régression linéaire :\n",
    "\n",
    "1. **Linéarité** : Les résidus doivent être distribués aléatoirement autour de zéro.\n",
    "2. **Homoscedasticité** : La variance des résidus doit être constante.\n",
    "3. **Absence de Patterns** : Les résidus ne doivent pas montrer de motifs spécifiques.\n",
    "\n",
    "Ces graphiques permettent de confirmer si les hypothèses de base de la régression linéaire sont respectées."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Tracer les résidus par rapport aux prédicteurs\n",
    "for feature in features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(x=X[feature], y=residuals)\n",
    "    plt.title(f'Residuals vs {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Histogramme des Résidus\n",
    "\n",
    "L'histogramme des résidus permet de vérifier la normalité des résidus. Pour que l'hypothèse de normalité soit respectée, les résidus doivent suivre une distribution en cloche (distribution normale).\n",
    "\n",
    "#### Q-Q Plot des Résidus\n",
    "\n",
    "Le Q-Q plot compare les quantiles des résidus aux quantiles d'une distribution normale. Si les points suivent une ligne droite diagonale, cela indique que les résidus sont normalement distribués. Cela valide l'hypothèse de normalité des résidus."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Heatmap des Corrélations\n",
    "\n",
    "Nous traçons une heatmap de la matrice de corrélation pour visualiser ces relations. La heatmap affiche les coefficients de corrélation entre chaque paire de features, avec des couleurs indiquant la force et la direction des corrélations.\n",
    "\n",
    "#### Absence de Multicolinéarité\n",
    "\n",
    "Cette visualisation permet de vérifier l'absence de multicolinéarité élevée entre les features. La multicolinéarité se produit lorsque deux ou plusieurs features sont fortement corrélées, ce qui peut compliquer l'interprétation des coefficients de régression et diminuer la performance du modèle. Des coefficients de corrélation proches de +1 ou -1 indiquent une forte multicolinéarité.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correlation_matrix = X.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Heatmap of Feature Correlations')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline de prétraitement\n",
    "\n",
    "#### Transformer personnalisé : YearToAgeTransformer\n",
    "\n",
    "Nous avons créé un transformateur personnalisé `YearToAgeTransformer` pour convertir les colonnes d'années (`YearBuilt`, `YearRemodAdd`, `GarageYrBlt`) en colonnes d'âges en soustrayant l'année actuelle. Transformer les années en âges permet de standardiser ces variables temporelles, facilitant l'interprétation et améliorant potentiellement la performance du modèle.\n",
    "\n",
    "#### Sélection des colonnes\n",
    "\n",
    "Nous avons sélectionné les colonnes numériques qui ne sont pas des années et qui ne sont pas la cible (`SalePrice`). Les colonnes catégorielles ordinales avec un ordre naturel ont également été identifiées, ainsi que les colonnes catégorielles nominales sans ordre naturel. Cette distinction permet d'appliquer des transformations spécifiques adaptées à chaque type de données, améliorant ainsi la qualité du prétraitement.\n",
    "\n",
    "#### Définition des catégories ordinales\n",
    "\n",
    "Les catégories pour les features ordinales sont définies explicitement, indiquant l'ordre de chacune. Fournir les catégories ordinales assure que l'encodage respecte l'ordre naturel des valeurs, ce qui est important pour la précision du modèle.\n",
    "\n",
    "#### Transformers\n",
    "\n",
    "1. **numeric_transformer** :\n",
    "   - **YearToAgeTransformer** : Convertit les années en âges.\n",
    "   - **SimpleImputer** : Impute les valeurs manquantes avec zéro.\n",
    "   - **StandardScaler** : Normalise les données pour assurer que chaque feature ait une moyenne de zéro et une variance de un.\n",
    "\n",
    "2. **ordinal_transformer** :\n",
    "   - **SimpleImputer** : Impute les valeurs manquantes avec 'NA'.\n",
    "   - **OrdinalEncoder** : Encode les catégories ordinales en respectant leur ordre naturel.\n",
    "\n",
    "3. **nominal_transformer** :\n",
    "   - **SimpleImputer** : Impute les valeurs manquantes avec 'NA'.\n",
    "   - **TargetEncoder** : Encode les catégories nominales en utilisant la cible.\n",
    "\n",
    "#### Imputation des valeurs manquantes avec zéro\n",
    "\n",
    "Nous avons choisi d'imputer les valeurs manquantes avec zéro plutôt qu'avec la moyenne ou le mode. \n",
    "\n",
    "**Avantages** :\n",
    "- **Simplicité** : L'imputation avec zéro est simple et rapide à implémenter.\n",
    "- **Préservation des données** : Cette méthode évite d'introduire des biais potentiels dans les données en utilisant des valeurs moyennes ou modales, qui pourraient ne pas être représentatives de certaines sous-populations.\n",
    "- **Indication de manque de données** : En remplaçant les valeurs manquantes par zéro, nous pouvons indiquer qu'il manquait des données à l'origine, ce qui peut être pris en compte dans les analyses ultérieures.\n",
    "\n",
    "**Inconvénients** :\n",
    "- **Perturbation des moyennes et variances** : L'ajout de zéros peut fausser les moyennes et les variances des features, particulièrement si les valeurs manquantes ne sont pas aléatoires.\n",
    "- **Interprétation** : Les zéros ajoutés peuvent être interprétés comme des valeurs légitimes, ce qui peut poser problème si zéro n'a pas de signification réelle pour certaines features.\n",
    "\n",
    "#### Combinaison des transformations\n",
    "\n",
    "Le `ColumnTransformer` combine les transformations pour chaque type de colonne, et passe les colonnes d'années transformées directement. Cette approche modulaire permet de traiter chaque type de données de manière spécifique et appropriée, assurant ainsi une préparation optimale des données pour le modèle de machine learning."
   ],
   "attachments": {},
   "metadata": {
    "datalore": {
     "node_id": "tNeJIsvXCnVrT66WiY5cLJ",
     "type": "MD",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Custom transformer to convert year columns to age columns\n",
    "class YearToAgeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, current_year):\n",
    "        self.current_year = current_year\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            X[col] = self.current_year - X[col]\n",
    "        return X\n",
    "\n",
    "# Define current year using datetime module\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Identify the year columns\n",
    "year_cols = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']\n",
    "\n",
    "# Define feature sets\n",
    "numerical_cols = [col for col in train.select_dtypes(include=['int64', 'float64']).columns if col not in year_cols and col != 'SalePrice']\n",
    "ordinal_features = [\n",
    "    'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "    'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual',\n",
    "    'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "    'PoolQC', 'Fence'\n",
    "]\n",
    "nominal_features = [col for col in train.select_dtypes(include=['object']).columns if col not in ordinal_features]\n",
    "\n",
    "# Define ordinal categories\n",
    "ordinal_categories = {\n",
    "    'OverallQual': list(range(1, 11)),\n",
    "    'OverallCond': list(range(1, 11)),\n",
    "    'ExterQual': ['NA','Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExterCond': ['NA','Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BsmtExposure': ['NA', 'No', 'Mn', 'Av', 'Gd'],\n",
    "    'BsmtFinType1': ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'BsmtFinType2': ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    'HeatingQC': ['NA','Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'KitchenQual': ['NA','Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'Functional': ['NA','Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n",
    "    'FireplaceQu': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageFinish': ['NA', 'Unf', 'RFn', 'Fin'],\n",
    "    'GarageQual': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageCond': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'PoolQC': ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'Fence': ['NA', 'MnWw', 'GdWo', 'MnPrv', 'GdPrv']\n",
    "}\n",
    "\n",
    "# Transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"year_to_age\", YearToAgeTransformer(current_year=current_year)),\n",
    "    (\"imputer\", SimpleImputer(strategy='constant', fill_value=0)),  # Using constant strategy for numerical columns with 0 as fill value\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NA')),  # Use 'NA' as the fill value for missing ordinal data\n",
    "    ('encoder', OrdinalEncoder(categories=[ordinal_categories[col] for col in ordinal_features], handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='NA')),  # Use 'NA' as the fill value for missing nominal data\n",
    "    ('encoder', TargetEncoder())\n",
    "])\n",
    "\n",
    "# Combine new features with existing transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('ord', ordinal_transformer, ordinal_features),\n",
    "        ('nom', nominal_transformer, nominal_features),\n",
    "        ('year', 'passthrough', year_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Add this to handle remaining columns\n",
    ")\n",
    "\n",
    "# Final pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('global_imputer', SimpleImputer(strategy='constant', fill_value=0))  # Add global imputer to handle any remaining NaNs with 0\n",
    "])"
   ],
   "metadata": {
    "datalore": {
     "node_id": "nGWDcFv0RTgyOjig9wtL1z",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explication et justification du traitement des données prétraitées\n",
    "\n",
    "#### Fit et transformation des données\n",
    "\n",
    "Nous ajustons le pipeline et transformons les données en utilisant `pipeline.fit_transform()` sur les données d'entraînement sans la colonne cible (`SalePrice`). Cette étape applique toutes les transformations définies dans le pipeline sur les données d'entraînement.\n",
    "\n",
    "#### Obtention des noms des features\n",
    "\n",
    "1. **Noms des features numériques** : Les noms des features numériques sont obtenus directement à partir des colonnes sélectionnées.\n",
    "2. **Noms des features ordinales** : Les noms des features ordinales sont également obtenus directement à partir des colonnes sélectionnées.\n",
    "3. **Noms des features nominales** : Les noms des features nominales sont extraits du transformateur de préprocesseur nominal, en utilisant `get_feature_names_out()` pour obtenir les noms des features après encodage.\n",
    "4. **Noms des features années** : Les noms des features d'années sont conservés tels quels.\n",
    "\n",
    "Ces étapes permettent de garder une trace des noms de toutes les features après transformation, ce qui est important pour l'interprétation et l'analyse des résultats du modèle.\n",
    "\n",
    "#### Conversion des données prétraitées en DataFrame\n",
    "\n",
    "Les données prétraitées sont converties en un DataFrame pandas avec les noms de colonnes appropriés. Cela facilite l'analyse et la manipulation des données prétraitées, permettant une intégration plus fluide avec d'autres outils et bibliothèques d'analyse de données.\n",
    "\n",
    "#### Vérification des NaNs\n",
    "\n",
    "Nous vérifions la présence de valeurs NaN dans le DataFrame prétraité. Cela nous assure que le pipeline de prétraitement a correctement imputé toutes les valeurs manquantes et qu'il n'y a pas de valeurs NaN restantes, ce qui pourrait nuire à la performance du modèle."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit and transform the data\n",
    "X_preprocessed = pipeline.fit_transform(train.drop(columns='SalePrice'), train['SalePrice'])\n",
    "\n",
    "# Get feature names\n",
    "numerical_feature_names = numerical_cols\n",
    "ordinal_feature_names = ordinal_features\n",
    "\n",
    "# Updated code to get nominal feature names correctly\n",
    "nominal_feature_names = nominal_features\n",
    "year_feature_names = year_cols\n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names = numerical_feature_names + ordinal_feature_names + nominal_feature_names + year_feature_names\n",
    "\n",
    "# Convert all feature names to strings\n",
    "all_feature_names = [str(name) for name in all_feature_names]\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
    "\n",
    "# Ensure all columns are strings\n",
    "X_preprocessed_df.columns = X_preprocessed_df.columns.astype(str)\n",
    "\n",
    "# Check for NaNs\n",
    "print(f'Number of NaN values in X_preprocessed: {np.isnan(X_preprocessed_df).sum().sum()}')\n",
    "\n",
    "# Updated code to check and rename duplicated feature names\n",
    "duplicated_features = X_preprocessed_df.columns[X_preprocessed_df.columns.duplicated()]\n",
    "if len(duplicated_features) > 0:\n",
    "    X_preprocessed_df.columns = [f\"{col}_{i}\" if col in duplicated_features else col for i, col in enumerate(X_preprocessed_df.columns)]\n",
    "\n",
    "# Print all feature names\n",
    "print(\"All feature names:\")\n",
    "print(X_preprocessed_df.columns.tolist())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformation de la variable cible\n",
    "\n",
    "Nous appliquons une transformation logarithmique (`np.log1p()`) à `SalePrice` pour normaliser sa distribution et réduire l'impact des valeurs extrêmes."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Transform the target variable\n",
    "y_transformed = np.log1p(train['SalePrice'])"
   ],
   "metadata": {
    "datalore": {
     "node_id": "D5wTrwyyQmFuqlb4bIQmai",
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "report_properties": {
      "rowId": "2BCUkfdjtpygtAEUi0scYJ"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modèle Lasso"
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the Lasso model\n",
    "lasso = Lasso()\n",
    "\n",
    "# Set up the hyperparameters for GridSearchCV\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0, 200.0]}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters with cross-validation\n",
    "lasso_cv = GridSearchCV(lasso, lasso_params, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_cv.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Get the best Lasso model\n",
    "best_lasso = lasso_cv.best_estimator_\n",
    "\n",
    "# Evaluate the best model using cross-validation\n",
    "cv_scores = cross_val_score(best_lasso, X_preprocessed, y_transformed, cv=5, scoring='neg_mean_squared_error')\n",
    "rmsle_cv_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Lasso CV Scores: \", rmsle_cv_scores)\n",
    "print(\"Average Lasso CV Score: \", np.mean(rmsle_cv_scores))\n",
    "\n",
    "# Visualize coefficients as a function of regularization\n",
    "alphas = np.logspace(-4, 4, 100)\n",
    "coefs = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso.set_params(alpha=alpha)\n",
    "    lasso.fit(X_preprocessed, y_transformed)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alphas, coefs)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('coefficients')\n",
    "plt.title('Lasso coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "KaFXMw9zFFZbU9fMoS1oFX",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modèle Ridge"
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the Ridge model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Set up the hyperparameters for GridSearchCV\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0, 200.0]}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters with cross-validation\n",
    "ridge_cv = GridSearchCV(ridge, ridge_params, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X_preprocessed_df, y_transformed)\n",
    "\n",
    "# Get the best Ridge model\n",
    "best_ridge = ridge_cv.best_estimator_\n",
    "\n",
    "# Evaluate the best model using cross-validation\n",
    "cv_scores = cross_val_score(best_ridge, X_preprocessed_df, y_transformed, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_cv_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Ridge CV Scores: \", rmse_cv_scores)\n",
    "print(\"Average Ridge CV Score: \", np.mean(rmse_cv_scores))\n",
    "\n",
    "# Visualize coefficients as a function of regularization\n",
    "alphas = np.logspace(-4, 7, 100)\n",
    "coefs = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge.set_params(alpha=alpha)\n",
    "    ridge.fit(X_preprocessed_df, y_transformed)\n",
    "    coefs.append(ridge.coef_)\n",
    "\n",
    "# Convert coefficients to a numpy array for easier manipulation\n",
    "coefs = np.array(coefs)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "for coef in coefs.T:\n",
    "    plt.plot(alphas, coef)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('coefficients')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axhline(0, color='grey', linestyle='--', linewidth=1)\n",
    "plt.xlim([min(alphas), max(alphas)])\n",
    "\n",
    "# Automatically adjust y-axis limits based on coefficients\n",
    "min_coefs, max_coefs = coefs.min(), coefs.max()\n",
    "plt.ylim([min_coefs, max_coefs])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "e3drqXc0OfgCBGGdhe81qJ",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modèle Elastic Net"
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the Elastic Net model\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Set up the hyperparameters for GridSearchCV\n",
    "elastic_net_params = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0, 100.0, 200.0],\n",
    "    'l1_ratio': [0.1, 0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters with cross-validation\n",
    "elastic_net_cv = GridSearchCV(elastic_net, elastic_net_params, cv=5, scoring='neg_mean_squared_error')\n",
    "elastic_net_cv.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Get the best Elastic Net model\n",
    "best_elastic_net = elastic_net_cv.best_estimator_\n",
    "\n",
    "# Evaluate the best model using cross-validation\n",
    "cv_scores = cross_val_score(best_elastic_net, X_preprocessed, y_transformed, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_cv_scores = np.sqrt(-cv_scores)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Elastic Net CV Scores: \", rmse_cv_scores)\n",
    "print(\"Average Elastic Net CV Score: \", np.mean(rmse_cv_scores))\n",
    "\n",
    "# Visualize coefficients as a function of regularization\n",
    "best_l1_ratio = best_elastic_net.l1_ratio\n",
    "alphas = np.logspace(-4, 4, 100)\n",
    "coefs = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    elastic_net.set_params(alpha=alpha, l1_ratio=best_l1_ratio)\n",
    "    elastic_net.fit(X_preprocessed, y_transformed)\n",
    "    coefs.append(elastic_net.coef_)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(alphas, coefs)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('coefficients')\n",
    "plt.title(f'Elastic Net coefficients as a function of the regularization (l1_ratio={best_l1_ratio})')\n",
    "plt.axis('tight')\n",
    "plt.xlim([min(alphas), max(alphas)])  # Ensure the x-axis limits cover the full range of alphas\n",
    "plt.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "DEaHGYnfOJiRYyoUE0C0Hc",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### SHAP\n",
    "\n",
    "#### Qu'est-ce que SHAP ?\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) est une méthode d'explication de modèles de machine learning basée sur les valeurs de Shapley de la théorie des jeux. Les valeurs de Shapley attribuent une importance à chaque feature pour chaque prédiction, permettant ainsi d'interpréter les modèles de machine learning de manière transparente et compréhensible.\n",
    "\n",
    "#### Pourquoi utilisons-nous SHAP ?\n",
    "\n",
    "1. **Transparence** : SHAP fournit une explication claire de l'importance de chaque feature pour chaque prédiction, ce qui aide à comprendre le fonctionnement interne des modèles de machine learning.\n",
    "2. **Interprétabilité** : En attribuant une valeur d'importance à chaque feature, SHAP permet de voir quelles variables ont le plus d'influence sur les prédictions du modèle.\n",
    "3. **Comparabilité** : Les valeurs SHAP sont comparables entre différents modèles, ce qui permet d'évaluer la contribution des features de manière cohérente.\n",
    "\n",
    "#### Comment utilisons-nous SHAP ?\n",
    "\n",
    "1. **Initialisation du SHAP Explainer** : Nous initialisons un Explainer SHAP adapté au modèle. Par exemple, pour les modèles complexes comme les réseaux de neurones ou les modèles SVR, nous utilisons `KernelExplainer`, tandis que pour les modèles basés sur les arbres (CatBoost, Random Forest, etc.), nous utilisons `TreeExplainer`.\n",
    "\n",
    "2. **Calcul des valeurs SHAP** : Nous calculons les valeurs SHAP pour un ensemble de données. Ces valeurs indiquent la contribution de chaque feature à chaque prédiction.\n",
    "\n",
    "3. **Visualisation des valeurs SHAP** : Nous utilisons diverses méthodes de visualisation fournies par SHAP pour interpréter les résultats. Les graphiques courants incluent les plots de résumé et les plots de force.\n",
    "\n",
    "   - **Résumé des valeurs SHAP** : Un résumé des valeurs SHAP montre l'importance moyenne des features, triées par ordre décroissant d'importance.\n",
    "\n",
    "   - **Plots de force** : Les plots de force visualisent l'impact de chaque feature pour une prédiction individuelle, montrant comment les valeurs des features influencent la sortie du modèle.\n",
    "\n",
    "#### Comment lire les visualisations SHAP ?\n",
    "\n",
    "1. **Résumé des valeurs SHAP** :\n",
    "   - **Axe des X** : Importance moyenne des features, mesurée par la valeur absolue des valeurs SHAP moyennes. Une plus grande valeur indique une plus grande importance pour les prédictions.\n",
    "   - **Axe des Y** : Liste des features. Les features sont triées par ordre décroissant d'importance.\n",
    "   - **Points** : Chaque point représente la valeur SHAP d'une feature pour une instance particulière. La couleur des points peut représenter la valeur de la feature (par exemple, haut en rouge et bas en bleu).\n",
    "\n",
    "   **Interprétation** : Les features en haut du graphique ont une plus grande influence sur les prédictions du modèle. Les valeurs SHAP permettent de comprendre quelles features sont les plus déterminantes pour les décisions du modèle.\n",
    "\n",
    "2. **Plots de force** :\n",
    "   - Visualisent l'impact de chaque feature sur une prédiction individuelle.\n",
    "   - Montrent comment les valeurs des features influencent la sortie du modèle en positif ou en négatif.\n",
    "\n",
    "   **Interprétation** : Ces plots aident à comprendre les raisons derrière une prédiction spécifique en montrant l'effet de chaque feature sur la prédiction finale."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modèle Gradient Boosting Regressor\n"
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the objective function for Optuna using RMSLE\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 7)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.2)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "    \n",
    "    # Initialize the model with suggested hyperparameters\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Use cross-validation to evaluate the model\n",
    "    cv_scores = cross_val_score(model, X_preprocessed_df, y_transformed, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmsle_cv_scores = np.sqrt(-cv_scores)\n",
    "    \n",
    "    # Return the average RMSLE score\n",
    "    return np.mean(rmsle_cv_scores)\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best trial\n",
    "best_trial = study.best_trial\n",
    "print(f'Best trial: {best_trial.params}')\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_params = best_trial.params\n",
    "best_boosting_model = GradientBoostingRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "best_boosting_model.fit(X_preprocessed_df, y_transformed)\n",
    "\n",
    "# Initialize the SHAP Explainer\n",
    "explainer = shap.Explainer(best_boosting_model)\n",
    "\n",
    "# Calculate SHAP values for the preprocessed data\n",
    "shap_values = explainer(X_preprocessed_df)\n",
    "\n",
    "# Visualize the SHAP values with a summary plot\n",
    "shap.summary_plot(shap_values, X_preprocessed_df, plot_type=\"bar\")\n",
    "\n",
    "# Use the cross-validation RMSLE from the best trial for the final evaluation\n",
    "best_rmsle = study.best_value\n",
    "print(f'Best RMSLE: {best_rmsle}')\n"
   ],
   "metadata": {
    "datalore": {
     "node_id": "4NTqfHXItnMnMnzfzvvWb3",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualisation des résultats de l'optimisation avec Optuna pour Gradient Boosting Regressor\n",
    "\n",
    "#### Historique de l'optimisation\n",
    "\n",
    "Nous traçons l'historique de l'optimisation pour le modèle Gradient Boosting en utilisant la fonction `plot_optimization_history()` d'Optuna.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Nombre d'essais effectués.\n",
    "- **Axe des Y** : Valeur de la fonction objectif (RMSLE) pour chaque essai.\n",
    "- **Points individuels** : Chaque point représente un essai individuel.\n",
    "- **Ligne** : Indique la tendance générale de l'optimisation.\n",
    "\n",
    "**Interprétation :**\n",
    "- Une courbe descendante indique que l'optimisation améliore la performance du modèle au fil des essais.\n",
    "- Une courbe stable indique une convergence vers une solution optimale.\n",
    "\n",
    "#### Importance des hyperparamètres\n",
    "\n",
    "Nous utilisons `plot_param_importances()` pour visualiser l'importance relative des hyperparamètres dans l'optimisation.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Importance relative des hyperparamètres.\n",
    "- **Axe des Y** : Hyperparamètres évalués.\n",
    "- **Barres** : Indiquent l'importance de chaque hyperparamètre.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les hyperparamètres avec des barres plus longues ont un impact plus significatif sur la performance du modèle.\n",
    "- Identifie les hyperparamètres les plus critiques à optimiser.\n",
    "\n",
    "#### Diagramme de coordonnées parallèles\n",
    "\n",
    "Nous traçons un diagramme de coordonnées parallèles avec `plot_parallel_coordinate()` pour explorer les relations entre les hyperparamètres et la fonction objectif.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes verticaux** : Représentent différents hyperparamètres et la fonction objectif.\n",
    "- **Lignes** : Chaque ligne représente un essai avec ses hyperparamètres et la performance correspondante.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les lignes montrant des combinaisons d'hyperparamètres réussies convergent vers des valeurs optimales.\n",
    "- Permet d'identifier les interactions entre les hyperparamètres.\n",
    "\n",
    "#### Slice plot\n",
    "\n",
    "Nous utilisons `plot_slice()` pour créer un graphique en tranches qui montre l'impact de chaque hyperparamètre individuellement.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes** : Chaque axe représente un hyperparamètre différent.\n",
    "- **Points** : Chaque point représente un essai avec sa valeur de fonction objectif.\n",
    "\n",
    "**Interprétation :**\n",
    "- Visualise comment chaque hyperparamètre influence la performance du modèle.\n",
    "- Identifie les valeurs optimales pour chaque hyperparamètre.\n",
    "\n",
    "#### Prédictions du modèle\n",
    "\n",
    "Nous prédictions les valeurs sur l'ensemble du dataset avec le meilleur modèle et traçons un graphique des valeurs réelles vs prédites.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Valeurs réelles (transformées).\n",
    "- **Axe des Y** : Valeurs prédites par le modèle.\n",
    "- **Points** : Chaque point représente une prédiction.\n",
    "- **Ligne rouge** : Ligne de référence où les valeurs réelles égalent les valeurs prédites.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les points proches de la ligne rouge indiquent de bonnes prédictions.\n",
    "- Évalue la performance globale du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Optimization History\n",
    "fig1 = vis.plot_optimization_history(study)\n",
    "fig1.update_layout(title='Optimization History for Gradient Boosting Regressor')\n",
    "fig1.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "Ljul2w85xH7bFlNn3pmm3v",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameter Importance\n",
    "fig2 = vis.plot_param_importances(study)\n",
    "fig2.update_layout(title='Hyperparameter Importance for Gradient Boosting Regressor')\n",
    "fig2.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "Jx4r0tclkYwKd94cr81pso",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Parallel Coordinate Plot\n",
    "fig3 = vis.plot_parallel_coordinate(study)\n",
    "fig3.update_layout(title='Parallel Coordinate Plot for Gradient Boosting Regressor')\n",
    "fig3.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "Cam7fnrJ2QnGHyrQpr8Tvw",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Slice Plot\n",
    "fig4 = vis.plot_slice(study)\n",
    "fig4.update_layout(title='Slice Plot for Gradient Boosting Regressor')\n",
    "fig4.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "8GSc4FV3r5ICCY1c5XmYx4",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Predict on the entire dataset with the best model\n",
    "y_pred_best = best_boosting_model.predict(X_preprocessed_df)\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_transformed, y_pred_best, alpha=0.5)\n",
    "plt.plot([min(y_transformed), max(y_transformed)], [min(y_transformed), max(y_transformed)], color='red', linestyle='--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "mGsAR2QjflDI0M2B0IusQv",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modèle XGBoost Regressor"
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the objective function\n",
    "def objective_xgbr(trial):\n",
    "    # Define hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0)\n",
    "    }\n",
    "    \n",
    "    # Initialize model\n",
    "    model = XGBRegressor(**params)\n",
    "    \n",
    "    # Perform cross-validation with RMSLE as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_preprocessed_df, y_transformed, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert negative mean squared error to positive RMSLE\n",
    "    rmsle_scores = np.sqrt(-cv_scores)\n",
    "    mean_rmsle = np.mean(rmsle_scores)\n",
    "    \n",
    "    return mean_rmsle\n",
    "\n",
    "# Create the study object and optimize the objective function\n",
    "study_xgbr = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_xgbr.optimize(objective_xgbr, n_trials=100)\n",
    "\n",
    "# Retrieve the best model and its parameters\n",
    "best_params = study_xgbr.best_trial.params\n",
    "best_xgbr_model = XGBRegressor(**best_params)\n",
    "best_xgbr_model.fit(X_preprocessed_df, y_transformed)\n",
    "\n",
    "# Initialize the SHAP explainer for the XGBoost model\n",
    "explainer = shap.TreeExplainer(best_xgbr_model)\n",
    "\n",
    "# Calculate SHAP values for the preprocessed data\n",
    "shap_values = explainer.shap_values(X_preprocessed_df)\n",
    "\n",
    "# Visualize the SHAP values with a summary plot\n",
    "shap.summary_plot(shap_values, X_preprocessed_df, plot_type=\"bar\")\n",
    "\n",
    "# Use the cross-validation RMSLE from the best trial for the final evaluation\n",
    "best_rmsle = study_xgbr.best_value\n",
    "print(f'Best RMSLE: {best_rmsle}')\n"
   ],
   "metadata": {
    "datalore": {
     "node_id": "dcW2UJo6QRs1TUiEWok04s",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualisation des résultats de l'optimisation avec Optuna pour XGBoost\n",
    "\n",
    "#### Historique de l'optimisation\n",
    "\n",
    "Nous traçons l'historique de l'optimisation pour le modèle XGBoost en utilisant la fonction `plot_optimization_history()` d'Optuna.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Nombre d'essais effectués.\n",
    "- **Axe des Y** : Valeur de la fonction objectif (RMSLE) pour chaque essai.\n",
    "- **Points individuels** : Chaque point représente un essai individuel.\n",
    "- **Ligne** : Indique la tendance générale de l'optimisation.\n",
    "\n",
    "**Interprétation :**\n",
    "- Une courbe descendante indique que l'optimisation améliore la performance du modèle au fil des essais.\n",
    "- Une courbe stable indique une convergence vers une solution optimale.\n",
    "\n",
    "#### Importance des hyperparamètres\n",
    "\n",
    "Nous utilisons `plot_param_importances()` pour visualiser l'importance relative des hyperparamètres dans l'optimisation.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Importance relative des hyperparamètres.\n",
    "- **Axe des Y** : Hyperparamètres évalués.\n",
    "- **Barres** : Indiquent l'importance de chaque hyperparamètre.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les hyperparamètres avec des barres plus longues ont un impact plus significatif sur la performance du modèle.\n",
    "- Identifie les hyperparamètres les plus critiques à optimiser.\n",
    "\n",
    "#### Diagramme de coordonnées parallèles\n",
    "\n",
    "Nous traçons un diagramme de coordonnées parallèles avec `plot_parallel_coordinate()` pour explorer les relations entre les hyperparamètres et la fonction objectif.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes verticaux** : Représentent différents hyperparamètres et la fonction objectif.\n",
    "- **Lignes** : Chaque ligne représente un essai avec ses hyperparamètres et la performance correspondante.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les lignes montrant des combinaisons d'hyperparamètres réussies convergent vers des valeurs optimales.\n",
    "- Permet d'identifier les interactions entre les hyperparamètres.\n",
    "\n",
    "#### Slice plot\n",
    "\n",
    "Nous utilisons `plot_slice()` pour créer un graphique en tranches qui montre l'impact de chaque hyperparamètre individuellement.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes** : Chaque axe représente un hyperparamètre différent.\n",
    "- **Points** : Chaque point représente un essai avec sa valeur de fonction objectif.\n",
    "\n",
    "**Interprétation :**\n",
    "- Visualise comment chaque hyperparamètre influence la performance du modèle.\n",
    "- Identifie les valeurs optimales pour chaque hyperparamètre.\n",
    "\n",
    "#### Prédictions du modèle\n",
    "\n",
    "Nous prédictions les valeurs sur l'ensemble du dataset avec le meilleur modèle XGBoost et traçons un graphique des valeurs réelles vs prédites.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Valeurs réelles (SalePrice).\n",
    "- **Axe des Y** : Valeurs prédites par le modèle (SalePrice).\n",
    "- **Points** : Chaque point représente une prédiction.\n",
    "- **Ligne noire en pointillés** : Ligne de référence où les valeurs réelles égalent les valeurs prédites.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les points proches de la ligne noire indiquent de bonnes prédictions.\n",
    "- Évalue la performance globale du modèle."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Optimization History\n",
    "fig1 = vis.plot_optimization_history(study_xgbr)\n",
    "fig1.update_layout(title='Optimization History for XGBoost Regressor')\n",
    "fig1.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "uvQBhR8sJ7xGgi6Uxb5W48",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameter Importance\n",
    "fig2 = vis.plot_param_importances(study_xgbr)\n",
    "fig2.update_layout(title='Hyperparameter Importance for XGBoost Regressor')\n",
    "fig2.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "FkfzGV1n92XSURYfUU3Ciw",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Parallel Coordinate Plot\n",
    "fig3 = vis.plot_parallel_coordinate(study_xgbr)\n",
    "fig3.update_layout(title='Parallel Coordinate Plot for XGBoost Regressor')\n",
    "fig3.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "9aaF3tL3r8GLrtgatNQSEo",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Slice Plot\n",
    "fig4 = vis.plot_slice(study_xgbr)\n",
    "fig4.update_layout(title='Slice Plot for XGBoost Regressor')\n",
    "fig4.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "OBknta8Kgl9jz2gs0RUStL",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Predict on the entire dataset using the best XGBoost model\n",
    "y_pred_xgbr = best_xgbr_model.predict(X_preprocessed_df)\n",
    "\n",
    "# Visualize Actual vs. Predicted Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=np.expm1(y_transformed), y=np.expm1(y_pred_xgbr), alpha=0.5)\n",
    "plt.plot([np.expm1(y_transformed).min(), np.expm1(y_transformed).max()], [np.expm1(y_transformed).min(), np.expm1(y_transformed).max()], 'k--', lw=3)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs. Predicted SalePrice (XGBoost Regressor)')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "datalore": {
     "node_id": "lpZmWHTUAgJ0gtJJj1Pii2",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modèle Random Forest Regressor"
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the objective function\n",
    "def objective_rfr(trial):\n",
    "    # Define hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "    }\n",
    "    \n",
    "    # Initialize model\n",
    "    model = RandomForestRegressor(**params)\n",
    "    \n",
    "    # Perform cross-validation with RMSLE as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_preprocessed_df, y_transformed, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert negative mean squared error to positive RMSLE\n",
    "    rmsle_scores = np.sqrt(-cv_scores)\n",
    "    mean_rmsle = np.mean(rmsle_scores)\n",
    "    \n",
    "    return mean_rmsle\n",
    "\n",
    "# Run optimization\n",
    "study_rfr = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_rfr.optimize(objective_rfr, n_trials=100)\n",
    "\n",
    "# Retrieve the best trial\n",
    "best_trial = study_rfr.best_trial\n",
    "print(f\"Best trial for Random Forest Regressor: {study_rfr.best_trial.params}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_params = best_trial.params\n",
    "best_rfr_model = RandomForestRegressor(**best_params)\n",
    "best_rfr_model.fit(X_preprocessed_df, y_transformed)\n",
    "\n",
    "# Initialize the SHAP Explainer\n",
    "explainer = shap.Explainer(best_rfr_model, X_preprocessed_df)\n",
    "\n",
    "# Calculate SHAP values for the preprocessed data\n",
    "shap_values = explainer(X_preprocessed_df)\n",
    "\n",
    "# Visualize the SHAP values with a summary plot\n",
    "shap.summary_plot(shap_values, X_preprocessed_df, plot_type=\"bar\")\n",
    "\n",
    "# Use the cross-validation RMSLE from the best trial for the final evaluation\n",
    "best_rmsle = study_rfr.best_value\n",
    "print(f'Best RMSLE: {best_rmsle}')"
   ],
   "metadata": {
    "datalore": {
     "node_id": "wM8mwYyUKwSvWuN7jZZssX",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualisation des résultats de l'optimisation avec Optuna pour Random Forest\n",
    "\n",
    "#### Historique de l'optimisation\n",
    "\n",
    "Nous traçons l'historique de l'optimisation pour le modèle Random Forest en utilisant la fonction `plot_optimization_history()` d'Optuna.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Nombre d'essais effectués.\n",
    "- **Axe des Y** : Valeur de la fonction objectif (RMSLE) pour chaque essai.\n",
    "- **Points individuels** : Chaque point représente un essai individuel.\n",
    "- **Ligne** : Indique la tendance générale de l'optimisation.\n",
    "\n",
    "**Interprétation :**\n",
    "- Une courbe descendante indique que l'optimisation améliore la performance du modèle au fil des essais.\n",
    "- Une courbe stable indique une convergence vers une solution optimale.\n",
    "\n",
    "#### Importance des hyperparamètres\n",
    "\n",
    "Nous utilisons `plot_param_importances()` pour visualiser l'importance relative des hyperparamètres dans l'optimisation.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Importance relative des hyperparamètres.\n",
    "- **Axe des Y** : Hyperparamètres évalués.\n",
    "- **Barres** : Indiquent l'importance de chaque hyperparamètre.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les hyperparamètres avec des barres plus longues ont un impact plus significatif sur la performance du modèle.\n",
    "- Identifie les hyperparamètres les plus critiques à optimiser.\n",
    "\n",
    "#### Diagramme de coordonnées parallèles\n",
    "\n",
    "Nous traçons un diagramme de coordonnées parallèles avec `plot_parallel_coordinate()` pour explorer les relations entre les hyperparamètres et la fonction objectif.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes verticaux** : Représentent différents hyperparamètres et la fonction objectif.\n",
    "- **Lignes** : Chaque ligne représente un essai avec ses hyperparamètres et la performance correspondante.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les lignes montrant des combinaisons d'hyperparamètres réussies convergent vers des valeurs optimales.\n",
    "- Permet d'identifier les interactions entre les hyperparamètres.\n",
    "\n",
    "#### Slice plot\n",
    "\n",
    "Nous utilisons `plot_slice()` pour créer un graphique en tranches qui montre l'impact de chaque hyperparamètre individuellement.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes** : Chaque axe représente un hyperparamètre différent.\n",
    "- **Points** : Chaque point représente un essai avec sa valeur de fonction objectif.\n",
    "\n",
    "**Interprétation :**\n",
    "- Visualise comment chaque hyperparamètre influence la performance du modèle.\n",
    "- Identifie les valeurs optimales pour chaque hyperparamètre.\n",
    "\n",
    "#### Prédictions du modèle\n",
    "\n",
    "Nous faisons des prédictions sur l'ensemble du dataset avec le meilleur modèle Random Forest et traçons un graphique des valeurs réelles vs prédites.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Valeurs réelles (SalePrice).\n",
    "- **Axe des Y** : Valeurs prédites par le modèle (SalePrice).\n",
    "- **Points** : Chaque point représente une prédiction.\n",
    "- **Ligne noire en pointillés** : Ligne de référence où les valeurs réelles égalent les valeurs prédites.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les points proches de la ligne noire indiquent de bonnes prédictions.\n",
    "- Évalue la performance globale du modèle."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Optimization History\n",
    "fig1 = vis.plot_optimization_history(study_rfr)\n",
    "fig1.update_layout(title='Optimization History for Random Forest Regressor')\n",
    "fig1.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "7DO7kY7zv51pzikqLAarZn",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameter Importance\n",
    "fig2 = vis.plot_param_importances(study_rfr)\n",
    "fig2.update_layout(title='Hyperparameter Importance for Random Forest Regressor')\n",
    "fig2.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "gpQgYTHo9NIpP7K629OW7m",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Parallel Coordinate Plot\n",
    "fig3 = vis.plot_parallel_coordinate(study_rfr)\n",
    "fig3.update_layout(title='Parallel Coordinate Plot for Random Forest Regressor')\n",
    "fig3.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "RjOxL4znRtrpmedyBMTebH",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Slice Plot\n",
    "fig4 = vis.plot_slice(study_rfr)\n",
    "fig4.update_layout(title='Slice Plot for Random Forest Regressor')\n",
    "fig4.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "nE71OPz7VkUASOm6DGG4zD",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Predict on the entire dataset using the best Random Forest model\n",
    "y_pred_rfr = best_rfr_model.predict(X_preprocessed_df)\n",
    "\n",
    "# Visualize Actual vs. Predicted Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=np.expm1(y_transformed), y=np.expm1(y_pred_rfr), alpha=0.5)\n",
    "plt.plot([np.expm1(y_transformed).min(), np.expm1(y_transformed).max()], [np.expm1(y_transformed).min(), np.expm1(y_transformed).max()], 'k--', lw=3)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs. Predicted SalePrice (Random Forest Regressor)')\n",
    "plt.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "c51XUMiSx19GbyyrguA7k0",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Modèle Support Vector Regressor\n",
    "#### Initialisation de l'Explainer SHAP\n",
    "\n",
    "Pour expliquer les prédictions du modèle SVR, nous utilisons SHAP (SHapley Additive exPlanations). Pour le modèle SVR, nous employons `KernelExplainer`, qui est adapté aux modèles non linéaires et complexes.\n",
    "\n",
    "**Note importante** : Nous utilisons un sous-ensemble des données (`X_preprocessed_df[:100]`) pour initialiser l'Explainer et calculer les valeurs SHAP. Cela est nécessaire pour des raisons de performance et de faisabilité computationnelle, car le calcul des valeurs SHAP pour un modèle SVR peut être très intensif en ressources.\n",
    "\n",
    "#### Calcul et interprétation des valeurs SHAP\n",
    "\n",
    "Nous calculons les valeurs SHAP pour le sous-ensemble des données. Les valeurs SHAP représentent l'importance de chaque feature pour chaque prédiction, permettant d'expliquer comment chaque feature influence les prédictions du modèle.\n",
    "\n",
    "**Visualisation avec SHAP** :\n",
    "- **Axe des X** : Importance des features, mesurée par les valeurs SHAP.\n",
    "- **Axe des Y** : Features, triées par ordre d'importance.\n",
    "- **Barres** : Représentent l'importance moyenne des features.\n",
    "\n",
    "Cette visualisation aide à comprendre les contributions des différentes features aux prédictions du modèle SVR, assurant une interprétation claire et transparente.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the objective function\n",
    "def objective_svr(trial):\n",
    "    # Define hyperparameters\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 1e-2, 10.0, log=True),\n",
    "        'epsilon': trial.suggest_float('epsilon', 1e-4, 1.0, log=True),\n",
    "        'gamma': trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    }\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SVR(**params)\n",
    "    \n",
    "    # Perform cross-validation with RMSLE as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_preprocessed_df, y_transformed, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert negative mean squared error to positive RMSLE\n",
    "    rmsle_scores = np.sqrt(-cv_scores)\n",
    "    mean_rmsle = np.mean(rmsle_scores)\n",
    "    \n",
    "    return mean_rmsle\n",
    "\n",
    "# Run optimization\n",
    "study_svr = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_svr.optimize(objective_svr, n_trials=100)\n",
    "\n",
    "# Retrieve the best trial\n",
    "best_svr_params = study_svr.best_trial.params\n",
    "print(f\"Best trial for SVR: {study_svr.best_trial.params}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_svr_model = SVR(**best_svr_params)\n",
    "best_svr_model.fit(X_preprocessed_df, y_transformed)\n",
    "\n",
    "# Initialize the SHAP Explainer\n",
    "explainer = shap.KernelExplainer(best_svr_model.predict, X_preprocessed_df[:100])  # Use a subset for kernel SHAP\n",
    "\n",
    "# Calculate SHAP values for the preprocessed data\n",
    "shap_values = explainer.shap_values(X_preprocessed_df[:100])\n",
    "\n",
    "# Use the cross-validation RMSLE from the best trial for the final evaluation\n",
    "best_rmsle = study_svr.best_value\n",
    "print(f'Best RMSLE: {best_rmsle}')"
   ],
   "metadata": {
    "datalore": {
     "node_id": "UF3tYOLTytE9S6rQu0j6Nn",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualisation des résultats de l'optimisation avec Optuna pour SVR\n",
    "\n",
    "#### Historique de l'optimisation\n",
    "\n",
    "Nous traçons l'historique de l'optimisation pour le modèle SVR en utilisant la fonction `plot_optimization_history()` d'Optuna.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Nombre d'essais effectués.\n",
    "- **Axe des Y** : Valeur de la fonction objectif (RMSLE) pour chaque essai.\n",
    "- **Points individuels** : Chaque point représente un essai individuel.\n",
    "- **Ligne** : Indique la tendance générale de l'optimisation.\n",
    "\n",
    "**Interprétation :**\n",
    "- Une courbe descendante indique que l'optimisation améliore la performance du modèle au fil des essais.\n",
    "- Une courbe stable indique une convergence vers une solution optimale.\n",
    "\n",
    "#### Importance des hyperparamètres\n",
    "\n",
    "Nous utilisons `plot_param_importances()` pour visualiser l'importance relative des hyperparamètres dans l'optimisation.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Importance relative des hyperparamètres.\n",
    "- **Axe des Y** : Hyperparamètres évalués.\n",
    "- **Barres** : Indiquent l'importance de chaque hyperparamètre.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les hyperparamètres avec des barres plus longues ont un impact plus significatif sur la performance du modèle.\n",
    "- Identifie les hyperparamètres les plus critiques à optimiser.\n",
    "\n",
    "#### Diagramme de coordonnées parallèles\n",
    "\n",
    "Nous traçons un diagramme de coordonnées parallèles avec `plot_parallel_coordinate()` pour explorer les relations entre les hyperparamètres et la fonction objectif.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes verticaux** : Représentent différents hyperparamètres et la fonction objectif.\n",
    "- **Lignes** : Chaque ligne représente un essai avec ses hyperparamètres et la performance correspondante.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les lignes montrant des combinaisons d'hyperparamètres réussies convergent vers des valeurs optimales.\n",
    "- Permet d'identifier les interactions entre les hyperparamètres.\n",
    "\n",
    "#### Slice plot\n",
    "\n",
    "Nous utilisons `plot_slice()` pour créer un graphique en tranches qui montre l'impact de chaque hyperparamètre individuellement.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes** : Chaque axe représente un hyperparamètre différent.\n",
    "- **Points** : Chaque point représente un essai avec sa valeur de fonction objectif.\n",
    "\n",
    "**Interprétation :**\n",
    "- Visualise comment chaque hyperparamètre influence la performance du modèle.\n",
    "- Identifie les valeurs optimales pour chaque hyperparamètre."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Optimization History\n",
    "fig1 = vis.plot_optimization_history(study_svr)\n",
    "fig1.update_layout(title='Optimization History for SVR')\n",
    "fig1.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "Os2kfuDXBipkrQaaKjZGdR",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameter Importance\n",
    "fig2 = vis.plot_param_importances(study_svr)\n",
    "fig2.update_layout(title='Hyperparameter Importance for SVR')\n",
    "fig2.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "9HfANGw0kr88iBSFD4lGfF",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Parallel Coordinate Plot\n",
    "fig3 = vis.plot_parallel_coordinate(study_svr)\n",
    "fig3.update_layout(title='Parallel Coordinate Plot for SVR')\n",
    "fig3.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "DRuaWOBP5uyeDypWXeTPKR",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Slice Plot\n",
    "fig4 = vis.plot_slice(study_svr)\n",
    "fig4.update_layout(title='Slice Plot for SVR')\n",
    "fig4.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "wwmOEDjBmxA1teEsAeyk16",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Modèle CatBoost Regressor"
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the objective function\n",
    "def objective_cat(trial):\n",
    "    # Define hyperparameters\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 50, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 1, 255)\n",
    "    }\n",
    "    \n",
    "    # Initialize model\n",
    "    model = CatBoostRegressor(**params, verbose=0)\n",
    "    \n",
    "    # Perform cross-validation with RMSLE as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_preprocessed_df, y_transformed, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert negative mean squared error to positive RMSLE\n",
    "    rmsle_scores = np.sqrt(-cv_scores)\n",
    "    mean_rmsle = np.mean(rmsle_scores)\n",
    "    \n",
    "    return mean_rmsle\n",
    "\n",
    "# Run optimization\n",
    "study_cat = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "study_cat.optimize(objective_cat, n_trials=100)\n",
    "\n",
    "# Retrieve the best trial\n",
    "best_cat_params = study_cat.best_trial.params\n",
    "print(f\"Best trial for CatBoost Regressor: {study_cat.best_trial.params}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_cat_model = CatBoostRegressor(**best_cat_params, verbose=0)\n",
    "best_cat_model.fit(X_preprocessed_df, y_transformed)\n",
    "\n",
    "# Initialize the SHAP Explainer\n",
    "explainer = shap.TreeExplainer(best_cat_model)\n",
    "\n",
    "# Calculate SHAP values for the preprocessed data\n",
    "shap_values = explainer.shap_values(X_preprocessed_df)\n",
    "\n",
    "# Visualize the SHAP values with a summary plot\n",
    "shap.summary_plot(shap_values, X_preprocessed_df, plot_type=\"bar\")\n",
    "\n",
    "# Use the cross-validation RMSLE from the best trial for the final evaluation\n",
    "best_rmsle = study_cat.best_value\n",
    "print(f'Best RMSLE: {best_rmsle}')"
   ],
   "metadata": {
    "datalore": {
     "node_id": "6OHQUX15D0XnGS6r0C6Yif",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualisation des résultats de l'optimisation avec Optuna pour CatBoost\n",
    "\n",
    "#### Historique de l'optimisation\n",
    "\n",
    "Nous traçons l'historique de l'optimisation pour le modèle CatBoost en utilisant la fonction `plot_optimization_history()` d'Optuna.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Nombre d'essais effectués.\n",
    "- **Axe des Y** : Valeur de la fonction objectif (RMSLE) pour chaque essai.\n",
    "- **Points individuels** : Chaque point représente un essai individuel.\n",
    "- **Ligne** : Indique la tendance générale de l'optimisation.\n",
    "\n",
    "**Interprétation :**\n",
    "- Une courbe descendante indique que l'optimisation améliore la performance du modèle au fil des essais.\n",
    "- Une courbe stable indique une convergence vers une solution optimale.\n",
    "\n",
    "#### Importance des hyperparamètres\n",
    "\n",
    "Nous utilisons `plot_param_importances()` pour visualiser l'importance relative des hyperparamètres dans l'optimisation.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Importance relative des hyperparamètres.\n",
    "- **Axe des Y** : Hyperparamètres évalués.\n",
    "- **Barres** : Indiquent l'importance de chaque hyperparamètre.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les hyperparamètres avec des barres plus longues ont un impact plus significatif sur la performance du modèle.\n",
    "- Identifie les hyperparamètres les plus critiques à optimiser.\n",
    "\n",
    "#### Diagramme de coordonnées parallèles\n",
    "\n",
    "Nous traçons un diagramme de coordonnées parallèles avec `plot_parallel_coordinate()` pour explorer les relations entre les hyperparamètres et la fonction objectif.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes verticaux** : Représentent différents hyperparamètres et la fonction objectif.\n",
    "- **Lignes** : Chaque ligne représente un essai avec ses hyperparamètres et la performance correspondante.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les lignes montrant des combinaisons d'hyperparamètres réussies convergent vers des valeurs optimales.\n",
    "- Permet d'identifier les interactions entre les hyperparamètres.\n",
    "\n",
    "#### Slice plot\n",
    "\n",
    "Nous utilisons `plot_slice()` pour créer un graphique en tranches qui montre l'impact de chaque hyperparamètre individuellement.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axes** : Chaque axe représente un hyperparamètre différent.\n",
    "- **Points** : Chaque point représente un essai avec sa valeur de fonction objectif.\n",
    "\n",
    "**Interprétation :**\n",
    "- Visualise comment chaque hyperparamètre influence la performance du modèle.\n",
    "- Identifie les valeurs optimales pour chaque hyperparamètre.\n",
    "\n",
    "#### Prédictions du modèle CatBoost\n",
    "\n",
    "Nous faisons des prédictions sur l'ensemble du dataset avec le meilleur modèle CatBoost et traçons un graphique des valeurs réelles vs prédites.\n",
    "\n",
    "**Comment lire le graphique :**\n",
    "- **Axe des X** : Valeurs réelles (SalePrice).\n",
    "- **Axe des Y** : Valeurs prédites par le modèle (SalePrice).\n",
    "- **Points** : Chaque point représente une prédiction.\n",
    "- **Ligne noire en pointillés** : Ligne de référence où les valeurs réelles égalent les valeurs prédites.\n",
    "\n",
    "**Interprétation :**\n",
    "- Les points proches de la ligne noire indiquent de bonnes prédictions.\n",
    "- Évalue la performance globale du modèle."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Optimization History\n",
    "fig1 = vis.plot_optimization_history(study_cat)\n",
    "fig1.update_layout(title='Optimization History for CatBoost Regressor')\n",
    "fig1.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "5ZQPTsOyqr1e6y7tY4Mti6",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameter Importance\n",
    "fig2 = vis.plot_param_importances(study_cat)\n",
    "fig2.update_layout(title='Hyperparameter Importance for CatBoost Regressor')\n",
    "fig2.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "BhqjSJGghI2upsC0I7pIqq",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Parallel Coordinate Plot\n",
    "fig3 = vis.plot_parallel_coordinate(study_cat)\n",
    "fig3.update_layout(title='Parallel Coordinate Plot for CatBoost Regressor')\n",
    "fig3.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "aLb5t0NRt9WdMXnEYaBLRq",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Predict on the entire dataset using the best SVR model\n",
    "y_pred_cat = best_cat_model.predict(X_preprocessed_df)\n",
    "\n",
    "# Visualize Actual vs. Predicted Values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=np.expm1(y_transformed), y=np.expm1(y_pred_cat), alpha=0.5)\n",
    "plt.plot([np.expm1(y_transformed).min(), np.expm1(y_transformed).max()], [np.expm1(y_transformed).min(), np.expm1(y_transformed).max()], 'k--', lw=3)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs. Predicted SalePrice (SVR)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Slice Plot\n",
    "fig4 = vis.plot_slice(study_cat)\n",
    "fig4.update_layout(title='Slice Plot for CatBoost Regressor')\n",
    "fig4.show()"
   ],
   "metadata": {
    "datalore": {
     "node_id": "cm788SsLSeY72U0j24ZuyI",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Préparation des prédictions finales et soumission pour différents modèles\n",
    "\n",
    "#### Chargement et transformation des données de test\n",
    "\n",
    "Nous chargeons les données de test à partir du fichier `test.csv`, en utilisant la colonne `Id` comme index. Ensuite, nous appliquons le pipeline de prétraitement (`pipeline.transform(test)`) aux données de test pour les transformer de la même manière que les données d'entraînement.\n",
    "\n",
    "#### Entraînement des modèles et prédictions\n",
    "\n",
    "Pour chaque modèle optimisé (CatBoost, Gradient Boosting, XGBoost, Random Forest, SVR, Lasso, Ridge, Elastic Net), nous réalisons les étapes suivantes :\n",
    "\n",
    "1. **Entraînement du modèle** : Le modèle est entraîné sur l'ensemble des données d'entraînement prétraitées (`X_preprocessed`) et la variable cible transformée (`y_transformed`).\n",
    "2. **Prédictions sur les données de test** : Nous faisons des prédictions sur les données de test transformées (`X_test_preprocessed`) en utilisant le modèle entraîné.\n",
    "3. **Inversion de la transformation logarithmique** : Nous appliquons l'inverse de la transformation logarithmique (`np.expm1`) sur les prédictions pour revenir à l'échelle originale des prix de vente.\n",
    "4. **Préparation du fichier de soumission** : Nous préparons un DataFrame pour la soumission avec les identifiants des maisons (`Id`) et les prix de vente prédites (`SalePrice`). Ce DataFrame est ensuite enregistré en tant que fichier CSV."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the test data\n",
    "test = pd.read_csv('test.csv', index_col='Id')\n",
    "\n",
    "# Transform the test data\n",
    "X_test_preprocessed = pipeline.transform(test)\n",
    "\n",
    "# Train the model on the entire training data using the best CatBoost model\n",
    "best_cat_model.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_cat_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Reverse the log transformation on the predictions\n",
    "y_pred_test_exp = np.expm1(y_pred_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test.index,\n",
    "    'SalePrice': y_pred_test_exp\n",
    "})\n",
    "\n",
    "# Save the submission file as submission.csv\n",
    "submission.to_csv('submission_cat_boost.csv', index=False)"
   ],
   "metadata": {
    "datalore": {
     "node_id": "bEdte8cHoaIibThvIEdkyv",
     "type": "CODE",
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model on the entire training data\n",
    "best_boosting_model.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_boosting_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Reverse the log transformation on the predictions\n",
    "y_pred_test_exp = np.expm1(y_pred_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test.index,\n",
    "    'SalePrice': y_pred_test_exp\n",
    "})\n",
    "\n",
    "# Save the submission file as submission.csv\n",
    "submission.to_csv('submission_boosting.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model on the entire training data\n",
    "best_xgbr_model.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_xgbr_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Reverse the log transformation on the predictions\n",
    "y_pred_test_exp = np.expm1(y_pred_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test.index,\n",
    "    'SalePrice': y_pred_test_exp\n",
    "})\n",
    "\n",
    "# Save the submission file as submission.csv\n",
    "submission.to_csv('submission_xgbr.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model on the entire training data\n",
    "best_rfr_model.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_rfr_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Reverse the log transformation on the predictions\n",
    "y_pred_test_exp = np.expm1(y_pred_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test.index,\n",
    "    'SalePrice': y_pred_test_exp\n",
    "})\n",
    "\n",
    "# Save the submission file as submission.csv\n",
    "submission.to_csv('submission_rfr.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model on the entire training data\n",
    "best_svr_model.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_svr_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Reverse the log transformation on the predictions\n",
    "y_pred_test_exp = np.expm1(y_pred_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test.index,\n",
    "    'SalePrice': y_pred_test_exp\n",
    "})\n",
    "\n",
    "# Save the submission file as submission.csv\n",
    "submission.to_csv('submission_svr.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model on the entire training data\n",
    "best_lasso.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_lasso.predict(X_test_preprocessed)\n",
    "\n",
    "# Reverse the log transformation on the predictions\n",
    "y_pred_test_exp = np.expm1(y_pred_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test.index,\n",
    "    'SalePrice': y_pred_test_exp\n",
    "})\n",
    "\n",
    "# Save the submission file as submission.csv\n",
    "submission.to_csv('submission_lasso.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model on the entire training data\n",
    "best_ridge.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_ridge.predict(X_test_preprocessed)\n",
    "\n",
    "# Reverse the log transformation on the predictions\n",
    "y_pred_test_exp = np.expm1(y_pred_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test.index,\n",
    "    'SalePrice': y_pred_test_exp\n",
    "})\n",
    "\n",
    "# Save the submission file as submission.csv\n",
    "submission.to_csv('submission_ridge.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model on the entire training data\n",
    "best_elastic_net.fit(X_preprocessed, y_transformed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = best_elastic_net.predict(X_test_preprocessed)\n",
    "\n",
    "# Reverse the log transformation on the predictions\n",
    "y_pred_test_exp = np.expm1(y_pred_test)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test.index,\n",
    "    'SalePrice': y_pred_test_exp\n",
    "})\n",
    "\n",
    "# Save the submission file as submission.csv\n",
    "submission.to_csv('submission_elastic.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Soumission des prédictions à Kaggle\n",
    "\n",
    "- **Configuration des identifiants** : Les identifiants de l'API Kaggle sont configurés.\n",
    "- **Liste des soumissions** : Une liste de fichiers de soumission et de noms de modèles est créée.\n",
    "- **Fonction de soumission** : Une fonction est définie pour soumettre les fichiers de prédiction à Kaggle.\n",
    "- **Soumission en boucle** : Tous les fichiers de soumission sont soumis à Kaggle dans une boucle.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up Kaggle API credentials\n",
    "os.environ['KAGGLE_USERNAME'] = 'my_kaggle_username'\n",
    "os.environ['KAGGLE_KEY'] = 'my_kaggle_api'\n",
    "\n",
    "# List of submission files and their respective model names\n",
    "submissions = [\n",
    "    (\"submission_cat_boost.csv\", \"CatBoost Model\"),\n",
    "    (\"submission_boosting.csv\", \"Boosting Model\"),\n",
    "    (\"submission_xgbr.csv\", \"XGBoost Regressor Model\"),\n",
    "    (\"submission_rfr.csv\", \"Random Forest Regressor Model\"),\n",
    "    (\"submission_svr.csv\", \"SVR Model\"),\n",
    "    (\"submission_lasso.csv\", \"Lasso Model\"),\n",
    "    (\"submission_ridge.csv\", \"Ridge Model\"),\n",
    "    (\"submission_elastic.csv\", \"Elastic Net Model\")\n",
    "]\n",
    "\n",
    "# Competition name\n",
    "competition_name = \"house-prices-advanced-regression-techniques\"\n",
    "\n",
    "# Function to submit to Kaggle\n",
    "def submit_to_kaggle(file_name, model_name, competition_name):\n",
    "    message = f\"Submission for {model_name}\"\n",
    "    command = f\"kaggle competitions submit -c {competition_name} -f {file_name} -m '{message}'\"\n",
    "    try:\n",
    "        output = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(f\"Successfully submitted {file_name}\")\n",
    "        print(output.stdout.decode())\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to submit {file_name}. Error: {e.stderr.decode()}\")\n",
    "\n",
    "# Submit all files\n",
    "for file_name, model_name in submissions:\n",
    "    submit_to_kaggle(file_name, model_name, competition_name)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### MLflow\n",
    "\n",
    "The MLflow logging block starts by initializing a new MLflow run, which creates a context for logging all subsequent data. It records the hyperparameters of the best CatBoost model, saving each parameter and its value. The best RMSLE (Root Mean Squared Logarithmic Error) value is also logged as a metric to evaluate model performance. The trained CatBoost model is then stored in MLflow for future use. The SHAP values are converted to a DataFrame, saved as a CSV file, and logged as an artifact in MLflow. Finally, the run ID is printed, allowing you to reference this particular experiment run in MLflow."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step to log the model into MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_params(best_cat_params)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"best_rmsle\", best_rmsle)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.catboost.log_model(best_cat_model, \"model\")\n",
    "    \n",
    "    # Log SHAP values\n",
    "    shap_values_df = pd.DataFrame(shap_values, columns=X_preprocessed_df.columns)\n",
    "    shap_values_df.to_csv(\"shap_values.csv\", index=False)\n",
    "    mlflow.log_artifact(\"shap_values.csv\")\n",
    "    \n",
    "    print(f\"Model logged in run {run.info.run_id}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualisation des résultats dans MLflow"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Start the MLflow server (run this in a separate terminal or cell if needed)\n",
    "!mlflow ui"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "datalore": {
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "base_environment": "default",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
